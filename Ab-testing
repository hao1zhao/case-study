{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.3","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# AB Testing \n1. [Problem Statement](#1) <br>\n2. [Hypothesis Testing](#2)<br>\n3. [Design the experiment](#3)<br>\n4. [Run the experiment](#4)<br>\n5. [Valiidity Checks](#5)<br>\n6. [Interpret Result](#6)<br>\n7. [Launch Decision](#7)<br>\n8. [Follow-Up Experiment](#8)<br>","metadata":{"_cell_guid":"19088ede-8fec-494e-bc1c-46a78211478c","_uuid":"e0d4dfc3eb59412c9046298044b673bcb1f32746"}},{"cell_type":"code","source":"import math as mt\nimport numpy as np\nimport pandas as pd\nfrom scipy.stats import norm","metadata":{"_cell_guid":"9a04b6ea-111a-4627-849f-53adf7efd40b","_uuid":"f4949401e2dab760c957525f17e90addf45fc9e8","execution":{"iopub.status.busy":"2022-08-10T00:14:02.078268Z","iopub.execute_input":"2022-08-10T00:14:02.078767Z","iopub.status.idle":"2022-08-10T00:14:03.573138Z","shell.execute_reply.started":"2022-08-10T00:14:02.078717Z","shell.execute_reply":"2022-08-10T00:14:03.572117Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## <font color=\"#00bfff\">1. Problem Statement <a id=\"1\"></a>\n***\n**Experiment Name:** \"Free Trial\" Screener. <br>\nIt is conducted by a website dedicated to teaching online - with the overall business goal of maximizing course completion by students. \n###  1.1 User journey <a class=\"anchor\" id=\"current\"></a>\n1. Visit Course website\n2. Open course page (`cookies` or called `pageviews`)\n3. Choose \"start free trial\" or \"access course materials\".\n     1. \"access course materials\"\n        1. Free users -> no charging\n     2. \"start free trial\" (`clicks`)\n        1. Less than 5 hours per week for learning -> <mark>Experiment change: suggested for switching to \"access course materials\"</mark>\n        2. 5 hours per week for learning -> stay here (`user-id`)\n           1. Course completion & Subscription (`enrollment` & `payment`)\n           2. Course completion & Cancel Subscription (`enrollment`)\n           3. Course incomplete & Subscription (`enrollment` & `payment`)\n           4. Course incomplete & Cancel Subscription (`enrollment`)\n\n### 1.2 Description of Experimented Before/After Change <a class=\"anchor\" id=\"description\"></a>\n\n**Before**\n* At the time of this experiment, courses currently have two options on the course overview page: \"start free trial\", and \"access course materials\".\n* If the student clicks \"start free trial\", they will be asked to enter their credit card information, and then they will be enrolled in a free trial for the paid version of the course. After 14 days, they will automatically be charged unless they cancel first.\n* If the student clicks \"access course materials\", they will be able to view the videos and take the quizzes for free, but they will not receive coaching support or a verified certificate, and they will not submit their final project for feedback.\n\n**After**\n* In the experiment, website tested a change where if the student clicked \"start free trial\", they were asked how much time they had available to devote to the course.\n* If the student indicated 5 or more hours per week, they would be taken through the checkout process as usual. If they indicated fewer than 5 hours per week, a message would appear indicating that Udacity courses usually require a greater time commitment for successful completion, and suggesting that the student might like to access the course materials for free.\n* At this point, the student would have the option to continue enrolling in the free trial, or access the course materials for free instead.\n\n### 1.3  Metrics Choice <a class=\"anchor\" id=\"metric\"></a>\nThe following are the possible metrics:\n\nAny place \"unique cookies\" are mentioned, the uniqueness is determined by day. (That is, the same cookie visiting on different days would be counted twice.) User-ids are automatically unique since the site does not allow the same user-id to enroll twice.\n\n- **Number of cookies**: That is, number of unique cookies to view the course overview page. ($d_{min}=3000$)\n- **Number of user-ids**: That is, number of users who enroll in the free trial. ($d_{min}=50$)\n- **Number of clicks**: That is, number of unique cookies to click the \"Start free trial\" button (which happens before the free trial screener is trigger). ($d_{min}=240$)\n- **Click-through-probability**: That is, number of unique cookies to click the \"Start free trial\" button divided by number of unique cookies to view the course overview page. ($d_{min}=0.01$)\n- **Gross conversion**: That is, number of user-ids to complete checkout and enroll in the free trial divided by number of unique cookies to click the \"Start free trial\" button. ($d_{min}=0.01$)\n- **Retention**: That is, number of user-ids to remain enrolled past the 14-day boundary (and thus make at least one payment) divided by the number of user-ids to complete checkout. ($d_{min}=0.01$)\n- **Net conversion**: That is, number of user-ids to remain enrolled past the 14-day boundary (and thus make at least one payment) divided by the number of unique cookies to click the \"Start free trial\" button. ($d_{min}=0.0075$)\n\n\n**Success metric :** directly measures the desired outcome and is connected to what you're trying to learn from the experiment, the success metric of an experiment must contain the following properties:\n* Observable in the short term\n* Sensitive to changes  i.e. top line (like retention) are often too insensitive to be impacted\n* Relevant for business in the long term\n\nTherefore, reasonable success metric becomes **Net conversion** and **Gross conversion**\n\n\nWe need two types of metrics for a successful experiment (or at least, a safe one); Guardrail and Success metrics.\nGuardrail metrics are used for \"sanity checks\", that is, to make sure our experiment (the way we presented a change to a part of the population, as well as the way we collected the data) is not inherently wrong. Basically, this means we pick metrics which we consider not to change (not to be affected) because of our experiment and later make sure these metrics don't change drastically between our control and experiment groups.<br>\nSuccess metrics on the other hand, are the metrics in which we expect to see a change, and are relevant to the business goals we aim to achieve.\n\n**Guardrail Metrics :** Guardrail metrics helps you mitigate the risk of your test, ensuring that key metrics are not adversely impacted.\n\nSelect metrcis you think may have an unintended negative effect becasuse your experiment(i.e.importment company metrics, metrics that can be canniballized by a success metric)\nBusiness Metric,\nnet conversion should not go down\nIn the same way, we set MDE for hypothesis, we set a Non-inferiority Margin for guardrail metrics... which represent the largest change we are willing to accept for a metrics to prove that it's not worth that before.\nTherefore, a reasonable Guardrail metric becomes **Click-through-probability** (number of unique cookies to click the \"Start free trial\" button divided by number of unique cookies to view the course overview page.)\ni.e. this metric should not <increase/decrease> more than ($d_{min}=0.01$) ","metadata":{}},{"cell_type":"markdown","source":"## <font color=\"#00bfff\">2. Hypothesis Testing <a id=\"2\"></a>\n***\nThe hypothesis was that this might set clearer expectations for students upfront, thus reducing the number of frustrated students who left the free trial because they didn't have enough time‚Äîwithout significantly reducing the number of students to continue past the free trial and eventually complete the course. If this hypothesis held true, the website could improve the overall student experience and improve coaches' capacity to support students who are likely to complete the course.\n### 2.1 State the hypothesis statements <a class=\"anchor\" id=\"hypothesis\"></a>\n* Null Hypothesis (H0): The number of student who past the free trial and eventually complete the course between the basline and variant algorithms are the same.\n* Alternative Hypothesis (H1):  The number of student who past the free trial and eventually complete the course between the basline and variant algorithms are different.\n\n### 2.2 Set statistical indicators <a class=\"anchor\" id=\"hypothesis\"></a>\n* Significance level: **Alpha = 0.05**  If the P-value is less than 0.05, then reject H0 and H1.\n* Statistical power: **ùõΩ=0.2**  The probability of decting an effect if the alterantive hypothesis is true.\n* Minimum detectable effect(MDE) : **2% lift**  Which marks the minimum change which is practically significant to the business. For instance, stating that any increase in retention that is under 2%, even if statistically significant, is not practical to the business.","metadata":{}},{"cell_type":"markdown","source":"## <font color=\"#00bfff\">3. Design the experiment <a id=\"3\"></a>\n***\nThe unit of diversion is a cookie, although if the student enrolls in the free trial, they are tracked by user-id from that point forward. The same user-id cannot enroll in the free trial twice. For users that do not enroll, their user-id is not tracked in the experiment, even if they were signed in when they visited the course overview page\n### 3.1 Set the randomization unit <a class=\"anchor\" id=\"hypothesis\"></a>\nOur randomization unit is page views\n\nGiven  ùõº=0.05  (significance level ) and  ùõΩ=0.2  (power), we want to estimate how many total pageviews (cookies who viewed the course overview page) we need in the experiment. This amount will be divided into tthe two groups: control and experiment\nAt this point, once we have estimated our metrics in the baseline (most importantly, their estimated variance) we cancalculate the munumal number of samples we need so that our experiment will have enough statistical power, as well as siginificance.\n\nThe minimum sample size for control and experiment groups, which provides probability of Type I Error $\\alpha$, Power $1-\\beta$, detectable effect $d$ and baseline conversion rate $p$ (simple hypothesis $H_0 : P_{cont} - P_{exp} = 0$ against simple alternative $H_A : P_{cont} - P_{exp} = d$  is:\n\n<center> <font size=\"5\"> $n = \\frac{(Z_{1-\\frac{\\alpha}{2}}sd_1 + Z_{1-\\beta}sd_2)^2}{d^2}$</font>, with: <br><br>\n$sd_1 = \\sqrt{p(1-p)+p(1-p)}$<br><br>\n$sd_2 = \\sqrt{p(1-p)+(p+d)(1-(1-(p+d))}$ </center><br>\n\nNow, let's break down what inputs we need and which calculations still need to be made. Regarding inputs, we have all the data we need:\nType 1 error ($\\alpha$), power ($1-\\beta$), detectable change ($d = D_{min}$) and baseline conversion rate (our $\\hat{p}$ ).\nWhat we need to calculate: \n* Get Z score for $1-\\frac{\\alpha}{2}$ and for $1-\\beta$\n* Get standard deviations 1 & 2, that is for both the baseline and for expected changed rate\nAll these components will finally yield the number we need.\n\n","metadata":{}},{"cell_type":"markdown","source":"### 3.2 Scaling Collected Data and Set up data pipelines to collect data<a class=\"anchor\" id=\"scale\"></a>\nFor all the calculations to follow we need to scale our collected counts estimates of metrics with the sample size we specified for variance estimation. In this case, \nwe are given the following rough estimates for these metrics (presumably collected from aggregates on daily traffic) <br>\n\n| Item | Description  | Estimator  |\n|:-:|:-:|:-:|\n| Number of cookies | Daily unique cookies to view course overview page  | 40,000  |\n| Number of clicks | Daily unique cookies to click Free Trial button  | 3,200 |\n| Number of enrollments | Free Trial enrollments per day  | 660  |\n| CTP | CTP on Free Trial button  | 0.08  |\n| Gross Conversion | Probability of enrolling, given a click  | 0.20625  |\n| Retention | Probability of payment, given enrollment  | 0.53  |\n| Net Conversion | Probability of payment, given click  | 0.109313 |","metadata":{}},{"cell_type":"code","source":"#Let's place this estimators into a dictionary for ease of use later\nbaseline = {\"Cookies\":40000,\"Clicks\":3200,\"Enrollments\":660,\"CTP\":0.08,\"GConversion\":0.20625,\n           \"Retention\":0.53,\"NConversion\":0.109313}","metadata":{"execution":{"iopub.status.busy":"2022-08-10T00:14:03.574477Z","iopub.execute_input":"2022-08-10T00:14:03.574905Z","iopub.status.idle":"2022-08-10T00:14:03.579274Z","shell.execute_reply.started":"2022-08-10T00:14:03.574855Z","shell.execute_reply":"2022-08-10T00:14:03.578427Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"### 3.3 Estimating Standard Deviation <a class=\"anchor\" id=\"sd\"></a>\nOnce we collected these estimates, we should estimate the standard deviation of a metric, this is computed for sample size calculations and confidence intervals for our results. The more variant a metric is, the harder it is to reach a significant result. Assuming a sample size of 5,000 cookies visiting the course overview page per day (as given in project's instructions) - we want to estimate a standard deviation, for the evaluation metrics only. The sample size we are considering should be smaller than the \"population\" we collected and small enough to have two groups with that size.","metadata":{}},{"cell_type":"code","source":"#Scale The counts estimates\nbaseline[\"Cookies\"] = 5000\nbaseline[\"Clicks\"]=baseline[\"Clicks\"]*(5000/40000)\nbaseline[\"Enrollments\"]=baseline[\"Enrollments\"]*(5000/40000)\nbaseline","metadata":{"execution":{"iopub.status.busy":"2022-08-10T00:14:03.580406Z","iopub.execute_input":"2022-08-10T00:14:03.580818Z","iopub.status.idle":"2022-08-10T00:14:03.603009Z","shell.execute_reply.started":"2022-08-10T00:14:03.580750Z","shell.execute_reply":"2022-08-10T00:14:03.602076Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"{'CTP': 0.08,\n 'Clicks': 400.0,\n 'Cookies': 5000,\n 'Enrollments': 82.5,\n 'GConversion': 0.20625,\n 'NConversion': 0.109313,\n 'Retention': 0.53}"},"metadata":{}}]},{"cell_type":"markdown","source":"### 3.4 Estimating Analytically <a class=\"anchor\" id=\"estimate\"></a>\nIn order to estimate variance analytically, we can assume metrics which are probabilities ($\\hat{p}$) are binomially distributed, so we can use this formula for the standard deviation: <br>\n<center><font size=\"4\">$SD=\\sqrt{\\frac{\\hat{p}*(1-\\hat{p})}{n}}$</font></center><br>\nThis assumption is only valid when the **unit of diversion** of the experiment is equal to the **unit of analysis** (the denominator of the metric formula). In the cases when this is not valid, the actual variance might be different and it is recommended to estimate it empirically.\n\nFor each metric, we need to plug two variables into the formula: <br>\n$\\hat{p}$ - baseline probability of the event to occur <br>\n$ n $ - sample size <br>\n\n\n* **Gross Conversion** - The baseline probability for Gross Conversion can be calculated by the number of users to enroll in a free trial divided by the number of cookies clicking the free trial. In other words, the probability of enrollment given a click. In this case, the unit of diversion (Cookies), that is the element by which we differentiate samples and assign them to control and experiment groups, is equall to the unit of analysis (cookies who click), that is the denominator of the formula to calculate Gross Conversion (GC). When this is the case, this analytic estimate of variance is sufficient.\n","metadata":{}},{"cell_type":"code","source":"# Let's get the p and n we need for Gross Conversion (GC)\n# and compute the Stansard Deviation(sd) rounded to 4 decimal digits.\nGC={}\nGC[\"d_min\"]=0.01\nGC[\"p\"]=baseline[\"GConversion\"]\n#p is given in this case - or we could calculate it from enrollments/clicks\nGC[\"n\"]=baseline[\"Clicks\"]\nGC[\"sd\"]=round(mt.sqrt((GC[\"p\"]*(1-GC[\"p\"]))/GC[\"n\"]),4)\nGC[\"sd\"]","metadata":{"execution":{"iopub.status.busy":"2022-08-10T00:14:03.605317Z","iopub.execute_input":"2022-08-10T00:14:03.605759Z","iopub.status.idle":"2022-08-10T00:14:03.615444Z","shell.execute_reply.started":"2022-08-10T00:14:03.605708Z","shell.execute_reply":"2022-08-10T00:14:03.614657Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"0.0202"},"metadata":{}}]},{"cell_type":"markdown","source":"* **Retention** - The baseline probability for retention is the number of paying users (enrolled after 14 free days) divided by the number of total enrolled users. In other words, the probability of payment, given enrollment. The sample size is the number of enrolled users. In this case, unit of diversion is not equal to unit of analysis (users who enrolled) so an analytical estimation is not enough - if we had the data for these estimates, we would want to estimate this variance empirically as well.","metadata":{}},{"cell_type":"code","source":"# Let's get the p and n we need for Retention(R)\n# and compute the Stansard Deviation(sd) rounded to 4 decimal digits.\nR={}\nR[\"d_min\"]=0.01\nR[\"p\"]=baseline[\"Retention\"]\nR[\"n\"]=baseline[\"Enrollments\"]\nR[\"sd\"]=round(mt.sqrt((R[\"p\"]*(1-R[\"p\"]))/R[\"n\"]),4)\nR[\"sd\"]","metadata":{"execution":{"iopub.status.busy":"2022-08-10T00:14:03.616614Z","iopub.execute_input":"2022-08-10T00:14:03.617057Z","iopub.status.idle":"2022-08-10T00:14:03.635411Z","shell.execute_reply.started":"2022-08-10T00:14:03.617004Z","shell.execute_reply":"2022-08-10T00:14:03.634487Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"0.0549"},"metadata":{}}]},{"cell_type":"markdown","source":"* **Net Conversion** - The baseline probability for the net conversion is the number of paying users divided by the number of cookies that clicked the free trial button. In other words, the probability of payment, given a click. The sample size is the number of cookies that clicked. In this case, the unit of analysis and diversion are equal so we expect a good enough estimation analytically.","metadata":{}},{"cell_type":"code","source":"# Let's get the p and n we need for Net Conversion (NC)\n# and compute the Standard Deviation (sd) rounded to 4 decimal digits.\nNC={}\nNC[\"d_min\"]=0.0075\nNC[\"p\"]=baseline[\"NConversion\"]\nNC[\"n\"]=baseline[\"Clicks\"]\nNC[\"sd\"]=round(mt.sqrt((NC[\"p\"]*(1-NC[\"p\"]))/NC[\"n\"]),4)\nNC[\"sd\"]","metadata":{"execution":{"iopub.status.busy":"2022-08-10T00:14:03.637121Z","iopub.execute_input":"2022-08-10T00:14:03.637673Z","iopub.status.idle":"2022-08-10T00:14:03.652468Z","shell.execute_reply.started":"2022-08-10T00:14:03.637607Z","shell.execute_reply":"2022-08-10T00:14:03.651502Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"0.0156"},"metadata":{}}]},{"cell_type":"code","source":"def get_sds(p,d):\n    sd1=mt.sqrt(2*p*(1-p))\n    sd2=mt.sqrt(p*(1-p)+(p+d)*(1-(p+d)))\n    x=[sd1,sd2]\n    return x","metadata":{"execution":{"iopub.status.busy":"2022-08-10T00:14:03.655045Z","iopub.execute_input":"2022-08-10T00:14:03.655378Z","iopub.status.idle":"2022-08-10T00:14:03.665683Z","shell.execute_reply.started":"2022-08-10T00:14:03.655312Z","shell.execute_reply":"2022-08-10T00:14:03.664644Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#Inputs: required alpha value (alpha should already fit the required test)\n#Returns: z-score for given alpha\ndef get_z_score(alpha):\n    return norm.ppf(alpha)\n\n# Inputs p-baseline conversion rate which is our estimated p and d-minimum detectable change\n# Returns\ndef get_sds(p,d):\n    sd1=mt.sqrt(2*p*(1-p))\n    sd2=mt.sqrt(p*(1-p)+(p+d)*(1-(p+d)))\n    sds=[sd1,sd2]\n    return sds\n\n# Inputs:sd1-sd for the baseline,sd2-sd for the expected change,alpha,beta,d-d_min,p-baseline estimate p\n# Returns: the minimum sample size required per group according to metric denominator\ndef get_sampSize(sds,alpha,beta,d):\n    n=pow((get_z_score(1-alpha/2)*sds[0]+get_z_score(1-beta)*sds[1]),2)/pow(d,2)\n    return n","metadata":{"execution":{"iopub.status.busy":"2022-08-10T00:14:03.667092Z","iopub.execute_input":"2022-08-10T00:14:03.667577Z","iopub.status.idle":"2022-08-10T00:14:03.682723Z","shell.execute_reply.started":"2022-08-10T00:14:03.667519Z","shell.execute_reply":"2022-08-10T00:14:03.681876Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### 3.5 Calculate Sample Size per Metric <a class=\"anchor\" id=\"calc\"></a>\nOK! Looks like we set up all the tools required for this part. We are now going to calculate the number of samples required for the experiment per metric, and we are subected to the fact that the highest sample size will be the effective size. This size should be considered in terms of efficacy of duration and exposure: how long will it take to get this many samples for the experiment.\n\nSo, to work more easily, let's add the d parameter to each of the metrics characteristics of each metric:","metadata":{}},{"cell_type":"code","source":"GC[\"d\"]=0.01\nR[\"d\"]=0.01\nNC[\"d\"]=0.0075","metadata":{"execution":{"iopub.status.busy":"2022-08-10T00:14:03.683836Z","iopub.execute_input":"2022-08-10T00:14:03.684306Z","iopub.status.idle":"2022-08-10T00:14:03.705208Z","shell.execute_reply.started":"2022-08-10T00:14:03.684242Z","shell.execute_reply":"2022-08-10T00:14:03.704289Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"Now, for the calculations\n* **Gross Conversion**","metadata":{}},{"cell_type":"code","source":"# Let's get an integer value for simplicity\nGC[\"SampSize\"]=round(get_sampSize(get_sds(GC[\"p\"],GC[\"d\"]),0.05,0.2,GC[\"d\"]))\nGC[\"SampSize\"]","metadata":{"execution":{"iopub.status.busy":"2022-08-10T00:14:03.706721Z","iopub.execute_input":"2022-08-10T00:14:03.707346Z","iopub.status.idle":"2022-08-10T00:14:03.725532Z","shell.execute_reply.started":"2022-08-10T00:14:03.707281Z","shell.execute_reply":"2022-08-10T00:14:03.724744Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"25835.0"},"metadata":{}}]},{"cell_type":"markdown","source":"This means we need at least 25,835 cookies who click the Free Trial button - per group! That means that if we got 400 clicks out of 5000 pageviews (`400/5000 = 0.08`) -> So, we are going to need `GC[\"SampSize\"]/0.08 = 322,938` pageviews, again ; per group! Finally, the total amount of samples per the Gross Conversion metric is:","metadata":{}},{"cell_type":"code","source":"GC[\"SampSize\"]=round(GC[\"SampSize\"]/0.08*2)\nGC[\"SampSize\"]","metadata":{"execution":{"iopub.status.busy":"2022-08-10T00:14:03.726578Z","iopub.execute_input":"2022-08-10T00:14:03.727051Z","iopub.status.idle":"2022-08-10T00:14:03.739103Z","shell.execute_reply.started":"2022-08-10T00:14:03.727005Z","shell.execute_reply":"2022-08-10T00:14:03.738382Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"645875.0"},"metadata":{}}]},{"cell_type":"markdown","source":"* Retention","metadata":{}},{"cell_type":"code","source":"# Getting a nice integer value\nR[\"SampSize\"]=round(get_sampSize(get_sds(R[\"p\"],R[\"d\"]),0.05,0.2,R[\"d\"]))\nR[\"SampSize\"]","metadata":{"execution":{"iopub.status.busy":"2022-08-10T00:14:03.740233Z","iopub.execute_input":"2022-08-10T00:14:03.740662Z","iopub.status.idle":"2022-08-10T00:14:03.754671Z","shell.execute_reply.started":"2022-08-10T00:14:03.740618Z","shell.execute_reply":"2022-08-10T00:14:03.753641Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"39087.0"},"metadata":{}}]},{"cell_type":"markdown","source":"This means that we need 39,087 users who enrolled per group! We have to first convert this to cookies who clicked, and then to cookies who viewed the page, then finally to multipky by two for both groups.","metadata":{}},{"cell_type":"code","source":"R[\"SampSize\"]=R[\"SampSize\"]/0.08/0.20625*2\nR[\"SampSize\"]","metadata":{"execution":{"iopub.status.busy":"2022-08-10T00:14:03.756143Z","iopub.execute_input":"2022-08-10T00:14:03.756583Z","iopub.status.idle":"2022-08-10T00:14:03.766551Z","shell.execute_reply.started":"2022-08-10T00:14:03.756479Z","shell.execute_reply":"2022-08-10T00:14:03.765841Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"4737818.1818181816"},"metadata":{}}]},{"cell_type":"markdown","source":"This takes us as high as over 4 million page views total, this is practically impossible because we know we get about 40,000 a day, this would take well over 100 days. This means we have to drop this metric and not continue to work with it because results from our experiment (which is much smaller) will be biased.\n* **Net Conversion**","metadata":{}},{"cell_type":"code","source":"# Getting a nice integer value\nNC[\"SampSize\"]=round(get_sampSize(get_sds(NC[\"p\"],NC[\"d\"]),0.05,0.2,NC[\"d\"]))\nNC[\"SampSize\"]","metadata":{"execution":{"iopub.status.busy":"2022-08-10T00:14:03.767680Z","iopub.execute_input":"2022-08-10T00:14:03.768104Z","iopub.status.idle":"2022-08-10T00:14:03.783401Z","shell.execute_reply.started":"2022-08-10T00:14:03.768060Z","shell.execute_reply":"2022-08-10T00:14:03.782602Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"27413.0"},"metadata":{}}]},{"cell_type":"markdown","source":"So, needing 27,413 cookies who click per group takes us all the way up to:","metadata":{}},{"cell_type":"code","source":"NC[\"SampSize\"]=NC[\"SampSize\"]/0.08*2\nNC[\"SampSize\"]","metadata":{"execution":{"iopub.status.busy":"2022-08-10T00:14:03.784455Z","iopub.execute_input":"2022-08-10T00:14:03.784849Z","iopub.status.idle":"2022-08-10T00:14:03.798150Z","shell.execute_reply.started":"2022-08-10T00:14:03.784805Z","shell.execute_reply":"2022-08-10T00:14:03.797450Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"685325.0"},"metadata":{}}]},{"cell_type":"markdown","source":"### 3.6 Duration of the experiment <a class=\"anchor\" id=\"calc\"></a>","metadata":{}},{"cell_type":"markdown","source":"We are all the way up to 685,325 cookies who view the page. This is more than what was needed for Gross Conversion, so this will be our number. Assuming we take 80% of each days pageviews, the data collection period for this experiment (the period in which the experiment is revealed) will be about 3 weeks.","metadata":{}},{"cell_type":"markdown","source":"## <font color=\"#00bfff\">4. Run the experiment <a id=\"4\"></a>\n***\nBefore we start our experiment we should know how these metrics behave before the change - that is, what are their baseline values.\n### 4.1 Loading collected data <a class=\"anchor\" id=\"collect_results\"></a>\n    ","metadata":{}},{"cell_type":"code","source":"# we use pandas to load datasets\ncontrol=pd.read_csv(\"../input/control-data/control_data.csv\")\nexperiment=pd.read_csv(\"../input/experiment-data/experiment_data.csv\")\ncontrol.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-10T00:14:03.799352Z","iopub.execute_input":"2022-08-10T00:14:03.799837Z","iopub.status.idle":"2022-08-10T00:14:03.849267Z","shell.execute_reply.started":"2022-08-10T00:14:03.799788Z","shell.execute_reply":"2022-08-10T00:14:03.848348Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"          Date  Pageviews  Clicks  Enrollments  Payments\n0  Sat, Oct 11       7723     687        134.0      70.0\n1  Sun, Oct 12       9102     779        147.0      70.0\n2  Mon, Oct 13      10511     909        167.0      95.0\n3  Tue, Oct 14       9871     836        156.0     105.0\n4  Wed, Oct 15      10014     837        163.0      64.0","text/html":"<div>\n<style>\n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Pageviews</th>\n      <th>Clicks</th>\n      <th>Enrollments</th>\n      <th>Payments</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Sat, Oct 11</td>\n      <td>7723</td>\n      <td>687</td>\n      <td>134.0</td>\n      <td>70.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Sun, Oct 12</td>\n      <td>9102</td>\n      <td>779</td>\n      <td>147.0</td>\n      <td>70.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Mon, Oct 13</td>\n      <td>10511</td>\n      <td>909</td>\n      <td>167.0</td>\n      <td>95.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Tue, Oct 14</td>\n      <td>9871</td>\n      <td>836</td>\n      <td>156.0</td>\n      <td>105.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Wed, Oct 15</td>\n      <td>10014</td>\n      <td>837</td>\n      <td>163.0</td>\n      <td>64.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## <font color=\"#00bfff\">5. Valiidity Checks <a  id=\"1\"></a>\n***\nFaulty experiments can lead to a bad decision.Make sure you do sanity checks of the experiment before you decide","metadata":{}},{"cell_type":"markdown","source":"\n### 5.1 Sanity <a class=\"anchor\" id=\"sanity\"></a>\nFirst thing we have to do before even beginning to analyze this experiment's results is sanity checks. These checks help verify that the experiment was conducted as expected and that other factors did not influence the data which we collected. This also makes sure that data collection was correct.\n\n\n* Free Trial button Click-Through-Probability\nWe will  check whether these obsereved values are like we expect (if in fact the experiment was not damaged.\n\n**Click-through-probability of the Free Trial Button**\nIn this case, we want to make sure the proportion of clicks given a pageview (our observed CTP) is about the same in both groups (since this was not expected to change due to the experiment). In order to check this out we will calculate the CTP in each group and calculate a confidence interval for the expected difference between them. \n\nIt is Bernouli popuplation : either clicks or doesn't click, we expect to see no difference ($CTP_{exp}-CTP_{cont}=0$), with an acceptable margin of error, dictated by our calculated confidence interval. The changes we should notice are for the calculation of the standard error - which in this case is a pooled standard error.Test statistic should follow Z-distribution.\n\n<center><font size=\"4\">$SD_{pool}=\\sqrt{\\hat{p_{pool}}(1-\\hat{p_{pool}}(\\frac{1}{N_{cont}}+\\frac{1}{N_{exp}})}$</font></center>\nwith <br> <center><font size=\"5\"> $\\hat{p_{pool}}=\\frac{x_{cont}+x_{exp}}{N_{cont}+N_{exp}}$ </font></center>\nWe should understand that CTP is a proportion in a population (amount of events x in a population n) like the amount of clicks out of the amount of pageviews..\n\n\n","metadata":{"_cell_guid":"a117e9b7-bfb5-4444-b1ed-e64903008bf9","_uuid":"6e8be49265f041c4e92e6b59f4c9d249176583c6"}},{"cell_type":"markdown","source":"A binomial random variable will be the number of successes we can expect to get out of N experiments, given the probability of a single success. So, if we consider being assigned to a group (control, for example) a success with probability 0.5 (random!), the number of samples which get assigned to the group is the value of our random binomial variable!","metadata":{}},{"cell_type":"code","source":"\nalpha=0.05","metadata":{"execution":{"iopub.status.busy":"2022-08-10T00:14:03.850445Z","iopub.execute_input":"2022-08-10T00:14:03.850874Z","iopub.status.idle":"2022-08-10T00:14:03.853954Z","shell.execute_reply.started":"2022-08-10T00:14:03.850799Z","shell.execute_reply":"2022-08-10T00:14:03.853260Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"pageviews_cont=control['Pageviews'].sum()\npageviews_exp=experiment['Pageviews'].sum()\nclicks_cont=control['Clicks'].sum()\nclicks_exp=experiment['Clicks'].sum()\npageviews_total=pageviews_cont+pageviews_exp\nclicks_total=clicks_cont+clicks_exp\nctp_cont=clicks_cont/pageviews_cont\nctp_exp=clicks_exp/pageviews_exp\nd_hat=round(ctp_exp-ctp_cont,4)\np_pooled=clicks_total/pageviews_total\nsd_pooled=mt.sqrt(p_pooled*(1-p_pooled)*(1/pageviews_cont+1/pageviews_exp))\nME=round(get_z_score(1-(alpha/2))*sd_pooled,4)\nprint (\"The confidence interval is between\",0-ME,\"and\",0+ME,\"; Is\",d_hat,\"within this range?\")","metadata":{"execution":{"iopub.status.busy":"2022-08-10T00:14:03.855284Z","iopub.execute_input":"2022-08-10T00:14:03.855679Z","iopub.status.idle":"2022-08-10T00:14:03.941780Z","shell.execute_reply.started":"2022-08-10T00:14:03.855624Z","shell.execute_reply":"2022-08-10T00:14:03.941010Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"The confidence interval is between -0.0013 and 0.0013 ; Is 0.0001 within this range?\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Since 0.0001 within -0.0013 and 0.0013, sanity check for CTP passed.\n\n### 5.2 Examining effect size <a class=\"anchor\" id=\"effect\"></a>\nThe next step is looking at the changes between the control and experiment groups with regard to our evaluation metrics to make sure the difference is there, that it is statistically significant and most importantly practically significant (the difference is \"big\" enough to make the experimented change beneficial to the company).\n\nNow, all that is left is to measure for each evaluation metric, the difference between the values from both groups. Then, we compute the confidence interval for that difference and test whether or not this confidence interval is both statistically and practically significant.\n\n* **Gross Conversion**\nA metric is statistically significant if the confidence interval does not include 0 (that is, you can be confident there was a change), and it is practically significant if the confidence interval does not include the practical significance boundary (that is, you can be confident there is a change that matters to the business.)\n\n> **Important:** The given spreadsheet lists pageviews and clicks for 39 days, while it only lists enrollments and payments for 23 days. So, when working with enrollments and payments we should notice using only the corresponding pageviews and clicks, and not all of them.","metadata":{"_cell_guid":"626356a4-5f7c-4e5b-a236-f355d8462ef8","_uuid":"cfb988eee490c8ac43589c61718433a6d6f0f88f"}},{"cell_type":"code","source":"# Count the total clicks from complete records only\nclicks_cont=control[\"Clicks\"].loc[control[\"Enrollments\"].notnull()].sum()\nclicks_exp=experiment[\"Clicks\"].loc[experiment[\"Enrollments\"].notnull()].sum()","metadata":{"_cell_guid":"8e13eba4-0daa-4220-a772-e1f371854d60","_uuid":"6d4d94df9e5afdfdf97703292b0ef9ac6c3e4251","execution":{"iopub.status.busy":"2022-08-10T00:14:03.942993Z","iopub.execute_input":"2022-08-10T00:14:03.943546Z","iopub.status.idle":"2022-08-10T00:14:03.963689Z","shell.execute_reply.started":"2022-08-10T00:14:03.943496Z","shell.execute_reply":"2022-08-10T00:14:03.962744Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"#Gross Conversion - number of enrollments divided by number of clicks\nenrollments_cont=control[\"Enrollments\"].sum()\nenrollments_exp=experiment[\"Enrollments\"].sum()\n\nGC_cont=enrollments_cont/clicks_cont\nGC_exp=enrollments_exp/clicks_exp\nGC_pooled=(enrollments_cont+enrollments_exp)/(clicks_cont+clicks_exp)\nGC_sd_pooled=mt.sqrt(GC_pooled*(1-GC_pooled)*(1/clicks_cont+1/clicks_exp))\nGC_ME=round(get_z_score(1-alpha/2)*GC_sd_pooled,4)\nGC_diff=round(GC_exp-GC_cont,4)\nprint(\"The change due to the experiment is\",GC_diff*100,\"%\")\nprint(\"Confidence Interval: [\",GC_diff-GC_ME,\",\",GC_diff+GC_ME,\"]\")\nprint (\"The change is statistically significant if the CI doesn't include 0. In that case, it is practically significant if\",-GC[\"d_min\"],\"is not in the CI as well.\")","metadata":{"_cell_guid":"5615673e-529c-452a-ad48-9186cb88f74b","_uuid":"3f17a8086726ee8cc01f150808f88fe8693a95a2","execution":{"iopub.status.busy":"2022-08-10T00:14:03.964985Z","iopub.execute_input":"2022-08-10T00:14:03.965553Z","iopub.status.idle":"2022-08-10T00:14:03.981319Z","shell.execute_reply.started":"2022-08-10T00:14:03.965486Z","shell.execute_reply":"2022-08-10T00:14:03.980387Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"The change due to the experiment is -2.06 %\nConfidence Interval: [ -0.0292 , -0.012 ]\nThe change is statistically significant if the CI doesn't include 0. In that case, it is practically significant if -0.01 is not in the CI as well.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"According to this result there was a change due to the experiment, that change was both statistically and practically significant. \nWe have a negative change of 2.06%, when we were willing to accept any change greater than 1%. This means the Gross Conversion rate of the experiment group (the one exposed to the change, i.e. asked how many hours they can devote to studying) has decreased as expected by 2% and this change was significant. This means  less people enrolled in the Free Trial after due to the pop-up. \n* **Net Conversion** \nThe hypothesis is the same as before just with net conversion instead of gross. At this point we expect the fraction of payers (out of the clicks) to decrease as well.","metadata":{"_cell_guid":"cbc93acb-0d0a-448c-8826-d69d515bfc3d","_uuid":"6f1263f81625002f07c5c015ccaa8a692a7ef35f"}},{"cell_type":"code","source":"#Net Conversion - number of payments divided by number of clicks\npayments_cont=control[\"Payments\"].sum()\npayments_exp=experiment[\"Payments\"].sum()\n\nNC_cont=payments_cont/clicks_cont\nNC_exp=payments_exp/clicks_exp\nNC_pooled=(payments_cont+payments_exp)/(clicks_cont+clicks_exp)\nNC_sd_pooled=mt.sqrt(NC_pooled*(1-NC_pooled)*(1/clicks_cont+1/clicks_exp))\nNC_ME=round(get_z_score(1-alpha/2)*NC_sd_pooled,4)\nNC_diff=round(NC_exp-NC_cont,4)\nprint(\"The change due to the experiment is\",NC_diff*100,\"%\")\nprint(\"Confidence Interval: [\",NC_diff-NC_ME,\",\",NC_diff+NC_ME,\"]\")\nprint (\"The change is statistically significant if the CI doesn't include 0. In that case, it is practically significant if\",NC[\"d_min\"],\"is not in the CI as well.\")","metadata":{"_cell_guid":"8cb352ad-fc92-4f21-b939-3874314ba8f4","_uuid":"83e99af5dea50f22629ccbd34faa196d4065172f","execution":{"iopub.status.busy":"2022-08-10T00:14:03.982718Z","iopub.execute_input":"2022-08-10T00:14:03.983275Z","iopub.status.idle":"2022-08-10T00:14:03.998118Z","shell.execute_reply.started":"2022-08-10T00:14:03.983202Z","shell.execute_reply":"2022-08-10T00:14:03.997179Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"The change due to the experiment is -0.49 %\nConfidence Interval: [ -0.0116 , 0.0018 ]\nThe change is statistically significant if the CI doesn't include 0. In that case, it is practically significant if 0.0075 is not in the CI as well.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"In this case we got a change size of less than a 0.5%, a very small decrease which is not statistically significant, and as such not practically significant.\n\n### 5.3 Double check with Sign Tests <a class=\"anchor\" id=\"sign_tests\"></a>\nIn a sign test we get another angle at analyzing the results we got - we check if the trend of change we observed (increase or decrease) was evident in the daily data. We are goint to compute the metric's value per day and then count on how many days the metric was lower in the experiment group and this will be the number of succssesses for our binomial variable. Once this is defined we can look at the proportion of days of success out of all the available days.\n\n### 5.3.1 Data Preparation <a class=\"anchor\" id=\"prep\"></a>","metadata":{"_cell_guid":"d36717f0-2607-4f67-b16f-593f3e620b81","_uuid":"fb574d1d1a255e7e9c7c12f72a1e15b34396b871"}},{"cell_type":"code","source":"#let's first create the dataset we need for this:\n# start by merging the two datasets\nfull=control.join(other=experiment,how=\"inner\",lsuffix=\"_cont\",rsuffix=\"_exp\")\n#Let's look at what we got\nfull.count()","metadata":{"_cell_guid":"d59fb882-ec0a-4cf9-9fd6-5e0271302ea6","_uuid":"aae6e4d96ac0d06b3bdfece143be74d58c0fade3","execution":{"iopub.status.busy":"2022-08-10T00:14:03.999522Z","iopub.execute_input":"2022-08-10T00:14:03.999889Z","iopub.status.idle":"2022-08-10T00:14:04.019605Z","shell.execute_reply.started":"2022-08-10T00:14:03.999841Z","shell.execute_reply":"2022-08-10T00:14:04.018763Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"Date_cont           37\nPageviews_cont      37\nClicks_cont         37\nEnrollments_cont    23\nPayments_cont       23\nDate_exp            37\nPageviews_exp       37\nClicks_exp          37\nEnrollments_exp     23\nPayments_exp        23\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"#now we only need the complete data records\nfull=full.loc[full[\"Enrollments_cont\"].notnull()]\nfull.count()","metadata":{"_cell_guid":"97817e5e-9c6b-4347-96f2-ad56a11bc60f","_uuid":"e2302f51793b1fcdb6c671783f0f7ab3ada7f62e","execution":{"iopub.status.busy":"2022-08-10T00:14:04.020650Z","iopub.execute_input":"2022-08-10T00:14:04.021015Z","iopub.status.idle":"2022-08-10T00:14:04.039055Z","shell.execute_reply.started":"2022-08-10T00:14:04.020973Z","shell.execute_reply":"2022-08-10T00:14:04.038327Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"Date_cont           23\nPageviews_cont      23\nClicks_cont         23\nEnrollments_cont    23\nPayments_cont       23\nDate_exp            23\nPageviews_exp       23\nClicks_exp          23\nEnrollments_exp     23\nPayments_exp        23\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# Perfect! Now, derive a new column for each metric, so we have it's daily values\n# We need a 1 if the experiment value is greater than the control value=\nx=full['Enrollments_cont']/full['Clicks_cont']\ny=full['Enrollments_exp']/full['Clicks_exp']\nfull['GC'] = np.where(x<y,1,0)\n# The same now for net conversion\nz=full['Payments_cont']/full['Clicks_cont']\nw=full['Payments_exp']/full['Clicks_exp']\nfull['NC'] = np.where(z<w,1,0)\nfull.head()","metadata":{"_cell_guid":"09f17781-7a21-4c4b-a239-e8ed2495f147","_uuid":"a5b14c1c27a3e2c78a1313c08824e05da12b2057","execution":{"iopub.status.busy":"2022-08-10T00:14:04.040316Z","iopub.execute_input":"2022-08-10T00:14:04.040683Z","iopub.status.idle":"2022-08-10T00:14:04.123473Z","shell.execute_reply.started":"2022-08-10T00:14:04.040640Z","shell.execute_reply":"2022-08-10T00:14:04.122707Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"     Date_cont  Pageviews_cont  Clicks_cont  Enrollments_cont  Payments_cont  \\\n0  Sat, Oct 11            7723          687             134.0           70.0   \n1  Sun, Oct 12            9102          779             147.0           70.0   \n2  Mon, Oct 13           10511          909             167.0           95.0   \n3  Tue, Oct 14            9871          836             156.0          105.0   \n4  Wed, Oct 15           10014          837             163.0           64.0   \n\n      Date_exp  Pageviews_exp  Clicks_exp  Enrollments_exp  Payments_exp  GC  \\\n0  Sat, Oct 11           7716         686            105.0          34.0   0   \n1  Sun, Oct 12           9288         785            116.0          91.0   0   \n2  Mon, Oct 13          10480         884            145.0          79.0   0   \n3  Tue, Oct 14           9867         827            138.0          92.0   0   \n4  Wed, Oct 15           9793         832            140.0          94.0   0   \n\n   NC  \n0   0  \n1   1  \n2   0  \n3   0  \n4   1  ","text/html":"<div>\n<style>\n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date_cont</th>\n      <th>Pageviews_cont</th>\n      <th>Clicks_cont</th>\n      <th>Enrollments_cont</th>\n      <th>Payments_cont</th>\n      <th>Date_exp</th>\n      <th>Pageviews_exp</th>\n      <th>Clicks_exp</th>\n      <th>Enrollments_exp</th>\n      <th>Payments_exp</th>\n      <th>GC</th>\n      <th>NC</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Sat, Oct 11</td>\n      <td>7723</td>\n      <td>687</td>\n      <td>134.0</td>\n      <td>70.0</td>\n      <td>Sat, Oct 11</td>\n      <td>7716</td>\n      <td>686</td>\n      <td>105.0</td>\n      <td>34.0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Sun, Oct 12</td>\n      <td>9102</td>\n      <td>779</td>\n      <td>147.0</td>\n      <td>70.0</td>\n      <td>Sun, Oct 12</td>\n      <td>9288</td>\n      <td>785</td>\n      <td>116.0</td>\n      <td>91.0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Mon, Oct 13</td>\n      <td>10511</td>\n      <td>909</td>\n      <td>167.0</td>\n      <td>95.0</td>\n      <td>Mon, Oct 13</td>\n      <td>10480</td>\n      <td>884</td>\n      <td>145.0</td>\n      <td>79.0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Tue, Oct 14</td>\n      <td>9871</td>\n      <td>836</td>\n      <td>156.0</td>\n      <td>105.0</td>\n      <td>Tue, Oct 14</td>\n      <td>9867</td>\n      <td>827</td>\n      <td>138.0</td>\n      <td>92.0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Wed, Oct 15</td>\n      <td>10014</td>\n      <td>837</td>\n      <td>163.0</td>\n      <td>64.0</td>\n      <td>Wed, Oct 15</td>\n      <td>9793</td>\n      <td>832</td>\n      <td>140.0</td>\n      <td>94.0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"GC_x=full.GC[full[\"GC\"]==1].count()\nNC_x=full.NC[full[\"NC\"]==1].count()\nn=full.NC.count()\nprint(\"No. of cases for GC:\",GC_x,'\\n',\n      \"No. of cases for NC:\",NC_x,'\\n',\n      \"No. of total cases\",n)","metadata":{"_cell_guid":"1b2a2c0e-bf4e-4a39-8e46-3d2c8ad17352","_uuid":"904d0fb8aee7d7c40a29174197b493716adee9fa","execution":{"iopub.status.busy":"2022-08-10T00:14:04.124486Z","iopub.execute_input":"2022-08-10T00:14:04.124854Z","iopub.status.idle":"2022-08-10T00:14:04.133524Z","shell.execute_reply.started":"2022-08-10T00:14:04.124814Z","shell.execute_reply":"2022-08-10T00:14:04.132812Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"No. of cases for GC: 4 \n No. of cases for NC: 10 \n No. of total cases 23\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### 5.3.2 Building a Sign Test <a class=\"anchor\" id=\"sign\"></a>\nWhat we want to do after we count the amount of days in which the experiment group had a higher metric value than that of the control group, is to see if that number is likely to be seen again in a new experiment (significance). We assume the chance of a day like this is random (50% chance to happen) and then use the binomial distribution with $p=0.5$ and the number of experiments (days) to tell us the probability of this happening according to a random chance.<br>\nSo, according to the binomial distribution with $p=0.5$ and $n=$total number of days; we want to now the probability of $x$ days being a success (higher metric value in experiment). Because we are doing a two-tailed test we want to double this probability and once we have we can call it the $p-value$ and compare it to our $\\alpha$. If the $p-value$ is greater than the $\\alpha$ the result is not significant and vice-versa.<br>\n<center><font size=\"4\"> $p(successes )=\\frac{n!}{x!(n-x)!}p^x(1-p)^{n-x}$ </font></center>\nRecall that a $p-value$ is the probability of observing a test statistic as or more extreme than that observed. If we observed 2 days like that, the $p-value$ for the test is: $p-value = P(x <= 2)$. We only need to remember the following:<br>\n\n","metadata":{"_cell_guid":"e57851c4-5cfc-4a22-b85a-db313de228e6","_uuid":"b6a395fc010e3843670a3f4a396340ee1dae5740"}},{"cell_type":"code","source":"#first a function for calculating probability of x=number of successes\ndef get_prob(x,n):\n    p=round(mt.factorial(n)/(mt.factorial(x)*mt.factorial(n-x))*0.5**x*0.5**(n-x),4)\n    return p\n#next a function to compute the pvalue from probabilities of maximum x\ndef get_2side_pvalue(x,n):\n    p=0\n    for i in range(0,x+1):\n        p=p+get_prob(i,n)\n    return 2*p","metadata":{"_cell_guid":"0cc3b899-b54b-4504-bca4-4e63fa594adb","_uuid":"e4db8dc9ead5aa4dd2389d03d8c037b2a3a30f28","execution":{"iopub.status.busy":"2022-08-10T00:14:04.134578Z","iopub.execute_input":"2022-08-10T00:14:04.134961Z","iopub.status.idle":"2022-08-10T00:14:04.142422Z","shell.execute_reply.started":"2022-08-10T00:14:04.134917Z","shell.execute_reply":"2022-08-10T00:14:04.141625Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"Finally, to conduct the sign test itself: we will calculate the p-value for each metric, using the counts `GC_x`,`NC_x` and `n` and the function `get_2side_pvalue`.","metadata":{"_cell_guid":"47e53586-6a19-4bc6-a625-cbdf23b29673","_uuid":"1742c1f207eba696a02adf533c03215d7fec00c8"}},{"cell_type":"code","source":"print (\"GC Change is significant if\",get_2side_pvalue(GC_x,n),\"is smaller than 0.05\")\nprint (\"NC Change is significant if\",get_2side_pvalue(NC_x,n),\"is smaller than 0.05\")","metadata":{"_cell_guid":"04d7c5b8-e859-4040-88e0-61180d05b167","_uuid":"f1f7624b436d510f36ca22df49eb1455b196485b","execution":{"iopub.status.busy":"2022-08-10T00:14:04.143687Z","iopub.execute_input":"2022-08-10T00:14:04.144204Z","iopub.status.idle":"2022-08-10T00:14:04.162663Z","shell.execute_reply.started":"2022-08-10T00:14:04.144142Z","shell.execute_reply":"2022-08-10T00:14:04.161733Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"GC Change is significant if 0.0026 is smaller than 0.05\nNC Change is significant if 0.6774 is smaller than 0.05\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We get the same conclusions as we got from our effect size calculation: the change in Gross conversion was indeed significant, while the change in Net conversion was not.","metadata":{}},{"cell_type":"markdown","source":"## <font color=\"#00bfff\">6. Interpret Result <a  id=\"6\"></a>\n***","metadata":{}},{"cell_type":"markdown","source":"Recall the definitions of the following metrics:\n- **Number of clicks** is the unique cookies to click the \"Start free trial\" button (which happens before the free trial screener is trigger). \n- **Enrollments**: Number of user-ids to enroll in the free trial that day.\n- **Payments**: Number of user-ids who enrolled on that day to remain enrolled for 14 days and thus make a payment. (Note that the date for this column is the start date, that is, the date of enrollment, rather than the date of the payment. The payment happened 14 days later. Because of this, the enrollments and payments are tracked for 14 fewer days than the other columns.)\n\nTo be more clear, the **Payments** is included in the **Enrollments**, which means there are two kinds of users:\n- Enrolled in the \"start free trial\" and make a payment\n- Enrolled in the \"start free trial\" and do not make a payment\n\nTherefore, if we can reduce the users of enrollments but keep the payments the same. We can assign the coaching services to potential paying users effectively and have the same revenue, leading to an increase in the users experience.\n\n\n\nBased on our analysis, The Confidence Interval of Gross conversion is statistical significance and practical significance with a 95% confidence level. Therefore, we are 95% confident that after applying the change (asking users who do not have 5 hours for learning per week to switch to \"access course materials\"), the overall enrollments decreased, which means some users decide not to enroll in the \"start free trial\". It will help website owner effectively distribute the human resource to the potential paying users.\n\nAdditionally, the Confidence Interval of the Net conversion is neither statistical significance or practical significance with 95% confidence level. Therefore, we are 95% confident that after applying the change, there is no difference between the control and experiment, which means we stay the payments at the same level but reduce the overall users of \"start free trial\". Because some users of \"start free trial\" may not continue to check out. Our target is to suggest this kind of users switch to \"access course materials\".\n\n\n\n","metadata":{}},{"cell_type":"markdown","source":"## <font color=\"#00bfff\">7.Launch Decision<a id=\"7\"></a>\n***\nAt this point, once we have seen that the actual underlying goal we had was not reached (increase fraction of paying users by asking them in advance if they have the time to invest in the course). It may have caused a change in Gross conversion, but it didn't for net conversion.\nConsidering this, my recomendation is not to launch, but rather to pursue other experiments.\n","metadata":{"_cell_guid":"2add23f9-3e0c-4b73-8f02-758dd9bb4f8a","_uuid":"e3ce6967a1ebfc3f84b268645bc71f16df53f36a"}},{"cell_type":"markdown","source":"## <font color=\"#00bfff\">8. Follow-Up Experiment: How to increase net conversion<a id=\"7\"></a>\n*** \n\nIf you wanted to increase net conversion,an efficent way is reducing the number of frustrated students who cancel early in the course","metadata":{}},{"cell_type":"markdown","source":"The potential frustrated students have two categories:\n- Category A: Students who do not finish the prerequisite courses.\n- Category B: Students who have issues but cannot find any help.\n\n`Cancellation rate` definition:\n- `Gross conversion` - `Net conversion`\n\n---\n\n### Experiment 1\n\nFor Category A students, Udacity can ask them when they click on \"start free trial\". This experiment is highly similar to the current experiment.\n\n- **Experiment**: A reminder of prerequisite courses for Free Trial\n- **Goal**: Minimize the course cancellation rate of **\"Free Trial\"** users by guiding the improper students to the basic course.\n- **Experiment Hypothesis**: The hypothesis was that this might set a clearer entrance for students who are able to finish the courses. For the students who need to finish prerequisite courses, guide them to the basic courses page, leading to a decrease in the number of frustrated students. The `clicks` will be tracked before the \"free trial\" started. If the experiment hypothesis is true, the experiment will have lower `enrollments`, leading to lower `Gross conversion` and higher `Net conversion`. Therefore, we have lower `Cancellation rate`.\n- **Experiment Change**: For the users who click on **\"start free trial\"**, Udacity will ask the users whether or not they have enough basic knowledge to complete the course.\n- **Unit of diversion**: cookies","metadata":{}},{"cell_type":"markdown","source":"---\n\n### Experiment 2\n\nFor Category B students, Udacity can track the students' stats. For instance, make a trigger system that lets the coach contact the students who submit the wrong answers more than three times for the same question.\n\n- **Experiment**: An initiative coaching service for frustrated students\n- **Goal**: Minimize the course cancellation rate of **\"Free Trial\"** users by providing initiative coaching services to the students.\n- **Experiment Hypothesis**: The hypothesis was that this might set a trigger system for providing initiative coaching services to the students who stuck in the quizzes or assignments. After helping the frustrated students, the course completion rate may be increased. If the hypothesis is true, the experiment will have a higher `Net conversion`. Therefore, we have a lower `Cancellation rate`.\n- **Experiment Change**: For the users who click on **\"start free trial\"** and have issues, Udacity provides initiative coaching services.\n- **Unit of diversion**: cookies","metadata":{}}]}